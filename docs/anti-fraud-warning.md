# Anti-Fraud Warning

Text-to-speech and voice cloning can be abused for scams (e.g., fake family emergencies, CEO fraud, refund scams, or deepfake customer calls). This project strongly condemns and forbids any fraudulent use of synthesized voices.

## Stay vigilant
- Be skeptical of urgent requests for money, gift cards, crypto, wire transfers, or credentialsâ€”verify through a trusted channel you initiate.
- Use call-back numbers you already know; do not rely on numbers, URLs, or attachments provided in a suspicious message.
- Enable multi-factor authentication and internal approval steps for payments and account changes.
- Train teams and family members to pause, verify, and escalate when something feels off.

## If you are building with this project
- Obtain consent before cloning or imitating a real person.
- Add safeguards: watermarking or audible disclosures, rate limits, logging, and access controls.
- Never deploy models or demos that encourage or enable impersonation or fraud.

## If you suspect abuse
- Stop the interaction immediately.
- Preserve evidence (call recordings, numbers, emails, headers).
- Report to your local authorities, relevant platforms, and impacted parties.

***Fraud harms real people. Do not use this software to deceive, impersonate, or exploit anyone.***
